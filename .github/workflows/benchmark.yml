name: MLServer Benchmarks

on:
  push:
    branches:
      - master
      - release/*
  pull_request:
    branches: [master]

jobs:
  benchmark:
    runs-on: ubuntu-latest
    env:
      MLSERVER_HOST: localhost
      MLSERVER_HTTP_PORT: 8080
      MLSERVER_GRPC_PORT: 8081
    strategy:
      matrix:
        scenario: ["inference-rest.js", "inference-grpc.js"]
    steps:
      - uses: actions/checkout@v2
      - name: Set up Python 3.8
        uses: actions/setup-python@v2
        with:
          python-version: 3.8
      - name: Install dependencies
        run: |
          make install-dev
      - name: Start Test Server
        working-directory: ./benchmarking
        run: |
          make start-testserver &
          sleep 10 # Wait for test server to come up
      - name: Benchmark
        uses: grafana/k6-action@v0.2.0
        with:
          filename: ./benchmarking/scenarios/${{ matrix.scenario }}
