name: MLServer Benchmarks

on:
  push:
    branches:
      - master
      - release/*
  pull_request:
    branches: [master]

jobs:
  benchmark-rest:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Set up Python 3.8
        uses: actions/setup-python@v2
        with:
          python-version: 3.8
      - name: Install dependencies
        run: |
          make install-dev
      - name: Start Test Server
        working-directory: ./benchmarking
        run: |
          make start-testserver &
        env:
          MLSERVER_HTTP_PORT: 8080
      - name: Benchmark REST
        uses: grafana/k6-action@v0.2.0
        with:
          filename: ./benchmarking/scenarios/inference-rest.js
        env:
          MLSERVER_HOST: 0.0.0.0
          MLSERVER_HTTP_PORT: 8080

  benchmark-grpc:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Set up Python 3.8
        uses: actions/setup-python@v2
        with:
          python-version: 3.8
      - name: Install dependencies
        run: |
          make install-dev
      - name: Start Test Server
        working-directory: ./benchmarking
        run: |
          make start-testserver &
        env:
          MLSERVER_GRPC_PORT: 8081
      - name: Benchmark gRPC
        uses: grafana/k6-action@v0.2.0
        with:
          filename: ./benchmarking/scenarios/inference-grpc.js
        env:
          MLSERVER_HOST: 0.0.0.0
          MLSERVER_GRPC_PORT: 8080
