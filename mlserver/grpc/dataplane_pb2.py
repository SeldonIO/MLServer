# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: dataplane.proto
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database

# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


DESCRIPTOR = _descriptor.FileDescriptor(
    name="dataplane.proto",
    package="inference",
    syntax="proto3",
    serialized_options=None,
    create_key=_descriptor._internal_create_key,
    serialized_pb=b'\n\x0f\x64\x61taplane.proto\x12\tinference"\x13\n\x11ServerLiveRequest""\n\x12ServerLiveResponse\x12\x0c\n\x04live\x18\x01 \x01(\x08"\x14\n\x12ServerReadyRequest"$\n\x13ServerReadyResponse\x12\r\n\x05ready\x18\x01 \x01(\x08"2\n\x11ModelReadyRequest\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x0f\n\x07version\x18\x02 \x01(\t"#\n\x12ModelReadyResponse\x12\r\n\x05ready\x18\x01 \x01(\x08"\x17\n\x15ServerMetadataRequest"K\n\x16ServerMetadataResponse\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x0f\n\x07version\x18\x02 \x01(\t\x12\x12\n\nextensions\x18\x03 \x03(\t"5\n\x14ModelMetadataRequest\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x0f\n\x07version\x18\x02 \x01(\t"\xc5\x04\n\x15ModelMetadataResponse\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x10\n\x08versions\x18\x02 \x03(\t\x12\x10\n\x08platform\x18\x03 \x01(\t\x12?\n\x06inputs\x18\x04 \x03(\x0b\x32/.inference.ModelMetadataResponse.TensorMetadata\x12@\n\x07outputs\x18\x05 \x03(\x0b\x32/.inference.ModelMetadataResponse.TensorMetadata\x12\x44\n\nparameters\x18\x06 \x03(\x0b\x32\x30.inference.ModelMetadataResponse.ParametersEntry\x1a\xe2\x01\n\x0eTensorMetadata\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x10\n\x08\x64\x61tatype\x18\x02 \x01(\t\x12\r\n\x05shape\x18\x03 \x03(\x03\x12S\n\nparameters\x18\x04 \x03(\x0b\x32?.inference.ModelMetadataResponse.TensorMetadata.ParametersEntry\x1aL\n\x0fParametersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12(\n\x05value\x18\x02 \x01(\x0b\x32\x19.inference.InferParameter:\x02\x38\x01\x1aL\n\x0fParametersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12(\n\x05value\x18\x02 \x01(\x0b\x32\x19.inference.InferParameter:\x02\x38\x01"\xd2\x06\n\x11ModelInferRequest\x12\x12\n\nmodel_name\x18\x01 \x01(\t\x12\x15\n\rmodel_version\x18\x02 \x01(\t\x12\n\n\x02id\x18\x03 \x01(\t\x12@\n\nparameters\x18\x04 \x03(\x0b\x32,.inference.ModelInferRequest.ParametersEntry\x12=\n\x06inputs\x18\x05 \x03(\x0b\x32-.inference.ModelInferRequest.InferInputTensor\x12H\n\x07outputs\x18\x06 \x03(\x0b\x32\x37.inference.ModelInferRequest.InferRequestedOutputTensor\x1a\x94\x02\n\x10InferInputTensor\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x10\n\x08\x64\x61tatype\x18\x02 \x01(\t\x12\r\n\x05shape\x18\x03 \x03(\x03\x12Q\n\nparameters\x18\x04 \x03(\x0b\x32=.inference.ModelInferRequest.InferInputTensor.ParametersEntry\x12\x30\n\x08\x63ontents\x18\x05 \x01(\x0b\x32\x1e.inference.InferTensorContents\x1aL\n\x0fParametersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12(\n\x05value\x18\x02 \x01(\x0b\x32\x19.inference.InferParameter:\x02\x38\x01\x1a\xd5\x01\n\x1aInferRequestedOutputTensor\x12\x0c\n\x04name\x18\x01 \x01(\t\x12[\n\nparameters\x18\x02 \x03(\x0b\x32G.inference.ModelInferRequest.InferRequestedOutputTensor.ParametersEntry\x1aL\n\x0fParametersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12(\n\x05value\x18\x02 \x01(\x0b\x32\x19.inference.InferParameter:\x02\x38\x01\x1aL\n\x0fParametersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12(\n\x05value\x18\x02 \x01(\x0b\x32\x19.inference.InferParameter:\x02\x38\x01"\xb8\x04\n\x12ModelInferResponse\x12\x12\n\nmodel_name\x18\x01 \x01(\t\x12\x15\n\rmodel_version\x18\x02 \x01(\t\x12\n\n\x02id\x18\x03 \x01(\t\x12\x41\n\nparameters\x18\x04 \x03(\x0b\x32-.inference.ModelInferResponse.ParametersEntry\x12@\n\x07outputs\x18\x05 \x03(\x0b\x32/.inference.ModelInferResponse.InferOutputTensor\x1a\x97\x02\n\x11InferOutputTensor\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x10\n\x08\x64\x61tatype\x18\x02 \x01(\t\x12\r\n\x05shape\x18\x03 \x03(\x03\x12S\n\nparameters\x18\x04 \x03(\x0b\x32?.inference.ModelInferResponse.InferOutputTensor.ParametersEntry\x12\x30\n\x08\x63ontents\x18\x05 \x01(\x0b\x32\x1e.inference.InferTensorContents\x1aL\n\x0fParametersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12(\n\x05value\x18\x02 \x01(\x0b\x32\x19.inference.InferParameter:\x02\x38\x01\x1aL\n\x0fParametersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12(\n\x05value\x18\x02 \x01(\x0b\x32\x19.inference.InferParameter:\x02\x38\x01"i\n\x0eInferParameter\x12\x14\n\nbool_param\x18\x01 \x01(\x08H\x00\x12\x15\n\x0bint64_param\x18\x02 \x01(\x03H\x00\x12\x16\n\x0cstring_param\x18\x03 \x01(\tH\x00\x42\x12\n\x10parameter_choice"\xd0\x01\n\x13InferTensorContents\x12\x15\n\rbool_contents\x18\x01 \x03(\x08\x12\x14\n\x0cint_contents\x18\x02 \x03(\x05\x12\x16\n\x0eint64_contents\x18\x03 \x03(\x03\x12\x15\n\ruint_contents\x18\x04 \x03(\r\x12\x17\n\x0fuint64_contents\x18\x05 \x03(\x04\x12\x15\n\rfp32_contents\x18\x06 \x03(\x02\x12\x15\n\rfp64_contents\x18\x07 \x03(\x01\x12\x16\n\x0e\x62ytes_contents\x18\x08 \x03(\x0c\x32\xfc\x03\n\x14GRPCInferenceService\x12K\n\nServerLive\x12\x1c.inference.ServerLiveRequest\x1a\x1d.inference.ServerLiveResponse"\x00\x12N\n\x0bServerReady\x12\x1d.inference.ServerReadyRequest\x1a\x1e.inference.ServerReadyResponse"\x00\x12K\n\nModelReady\x12\x1c.inference.ModelReadyRequest\x1a\x1d.inference.ModelReadyResponse"\x00\x12W\n\x0eServerMetadata\x12 .inference.ServerMetadataRequest\x1a!.inference.ServerMetadataResponse"\x00\x12T\n\rModelMetadata\x12\x1f.inference.ModelMetadataRequest\x1a .inference.ModelMetadataResponse"\x00\x12K\n\nModelInfer\x12\x1c.inference.ModelInferRequest\x1a\x1d.inference.ModelInferResponse"\x00\x62\x06proto3',
)


_SERVERLIVEREQUEST = _descriptor.Descriptor(
    name="ServerLiveRequest",
    full_name="inference.ServerLiveRequest",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    create_key=_descriptor._internal_create_key,
    fields=[],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=30,
    serialized_end=49,
)


_SERVERLIVERESPONSE = _descriptor.Descriptor(
    name="ServerLiveResponse",
    full_name="inference.ServerLiveResponse",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    create_key=_descriptor._internal_create_key,
    fields=[
        _descriptor.FieldDescriptor(
            name="live",
            full_name="inference.ServerLiveResponse.live",
            index=0,
            number=1,
            type=8,
            cpp_type=7,
            label=1,
            has_default_value=False,
            default_value=False,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=51,
    serialized_end=85,
)


_SERVERREADYREQUEST = _descriptor.Descriptor(
    name="ServerReadyRequest",
    full_name="inference.ServerReadyRequest",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    create_key=_descriptor._internal_create_key,
    fields=[],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=87,
    serialized_end=107,
)


_SERVERREADYRESPONSE = _descriptor.Descriptor(
    name="ServerReadyResponse",
    full_name="inference.ServerReadyResponse",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    create_key=_descriptor._internal_create_key,
    fields=[
        _descriptor.FieldDescriptor(
            name="ready",
            full_name="inference.ServerReadyResponse.ready",
            index=0,
            number=1,
            type=8,
            cpp_type=7,
            label=1,
            has_default_value=False,
            default_value=False,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=109,
    serialized_end=145,
)


_MODELREADYREQUEST = _descriptor.Descriptor(
    name="ModelReadyRequest",
    full_name="inference.ModelReadyRequest",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    create_key=_descriptor._internal_create_key,
    fields=[
        _descriptor.FieldDescriptor(
            name="name",
            full_name="inference.ModelReadyRequest.name",
            index=0,
            number=1,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=b"".decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="version",
            full_name="inference.ModelReadyRequest.version",
            index=1,
            number=2,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=b"".decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=147,
    serialized_end=197,
)


_MODELREADYRESPONSE = _descriptor.Descriptor(
    name="ModelReadyResponse",
    full_name="inference.ModelReadyResponse",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    create_key=_descriptor._internal_create_key,
    fields=[
        _descriptor.FieldDescriptor(
            name="ready",
            full_name="inference.ModelReadyResponse.ready",
            index=0,
            number=1,
            type=8,
            cpp_type=7,
            label=1,
            has_default_value=False,
            default_value=False,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=199,
    serialized_end=234,
)


_SERVERMETADATAREQUEST = _descriptor.Descriptor(
    name="ServerMetadataRequest",
    full_name="inference.ServerMetadataRequest",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    create_key=_descriptor._internal_create_key,
    fields=[],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=236,
    serialized_end=259,
)


_SERVERMETADATARESPONSE = _descriptor.Descriptor(
    name="ServerMetadataResponse",
    full_name="inference.ServerMetadataResponse",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    create_key=_descriptor._internal_create_key,
    fields=[
        _descriptor.FieldDescriptor(
            name="name",
            full_name="inference.ServerMetadataResponse.name",
            index=0,
            number=1,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=b"".decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="version",
            full_name="inference.ServerMetadataResponse.version",
            index=1,
            number=2,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=b"".decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="extensions",
            full_name="inference.ServerMetadataResponse.extensions",
            index=2,
            number=3,
            type=9,
            cpp_type=9,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=261,
    serialized_end=336,
)


_MODELMETADATAREQUEST = _descriptor.Descriptor(
    name="ModelMetadataRequest",
    full_name="inference.ModelMetadataRequest",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    create_key=_descriptor._internal_create_key,
    fields=[
        _descriptor.FieldDescriptor(
            name="name",
            full_name="inference.ModelMetadataRequest.name",
            index=0,
            number=1,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=b"".decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="version",
            full_name="inference.ModelMetadataRequest.version",
            index=1,
            number=2,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=b"".decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=338,
    serialized_end=391,
)


_MODELMETADATARESPONSE_TENSORMETADATA_PARAMETERSENTRY = _descriptor.Descriptor(
    name="ParametersEntry",
    full_name="inference.ModelMetadataResponse.TensorMetadata.ParametersEntry",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    create_key=_descriptor._internal_create_key,
    fields=[
        _descriptor.FieldDescriptor(
            name="key",
            full_name="inference.ModelMetadataResponse.TensorMetadata.ParametersEntry.key",
            index=0,
            number=1,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=b"".decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="value",
            full_name="inference.ModelMetadataResponse.TensorMetadata.ParametersEntry.value",
            index=1,
            number=2,
            type=11,
            cpp_type=10,
            label=1,
            has_default_value=False,
            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=b"8\001",
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=821,
    serialized_end=897,
)

_MODELMETADATARESPONSE_TENSORMETADATA = _descriptor.Descriptor(
    name="TensorMetadata",
    full_name="inference.ModelMetadataResponse.TensorMetadata",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    create_key=_descriptor._internal_create_key,
    fields=[
        _descriptor.FieldDescriptor(
            name="name",
            full_name="inference.ModelMetadataResponse.TensorMetadata.name",
            index=0,
            number=1,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=b"".decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="datatype",
            full_name="inference.ModelMetadataResponse.TensorMetadata.datatype",
            index=1,
            number=2,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=b"".decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="shape",
            full_name="inference.ModelMetadataResponse.TensorMetadata.shape",
            index=2,
            number=3,
            type=3,
            cpp_type=2,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="parameters",
            full_name="inference.ModelMetadataResponse.TensorMetadata.parameters",
            index=3,
            number=4,
            type=11,
            cpp_type=10,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
    ],
    extensions=[],
    nested_types=[
        _MODELMETADATARESPONSE_TENSORMETADATA_PARAMETERSENTRY,
    ],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=671,
    serialized_end=897,
)

_MODELMETADATARESPONSE_PARAMETERSENTRY = _descriptor.Descriptor(
    name="ParametersEntry",
    full_name="inference.ModelMetadataResponse.ParametersEntry",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    create_key=_descriptor._internal_create_key,
    fields=[
        _descriptor.FieldDescriptor(
            name="key",
            full_name="inference.ModelMetadataResponse.ParametersEntry.key",
            index=0,
            number=1,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=b"".decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="value",
            full_name="inference.ModelMetadataResponse.ParametersEntry.value",
            index=1,
            number=2,
            type=11,
            cpp_type=10,
            label=1,
            has_default_value=False,
            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=b"8\001",
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=821,
    serialized_end=897,
)

_MODELMETADATARESPONSE = _descriptor.Descriptor(
    name="ModelMetadataResponse",
    full_name="inference.ModelMetadataResponse",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    create_key=_descriptor._internal_create_key,
    fields=[
        _descriptor.FieldDescriptor(
            name="name",
            full_name="inference.ModelMetadataResponse.name",
            index=0,
            number=1,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=b"".decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="versions",
            full_name="inference.ModelMetadataResponse.versions",
            index=1,
            number=2,
            type=9,
            cpp_type=9,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="platform",
            full_name="inference.ModelMetadataResponse.platform",
            index=2,
            number=3,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=b"".decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="inputs",
            full_name="inference.ModelMetadataResponse.inputs",
            index=3,
            number=4,
            type=11,
            cpp_type=10,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="outputs",
            full_name="inference.ModelMetadataResponse.outputs",
            index=4,
            number=5,
            type=11,
            cpp_type=10,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="parameters",
            full_name="inference.ModelMetadataResponse.parameters",
            index=5,
            number=6,
            type=11,
            cpp_type=10,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
    ],
    extensions=[],
    nested_types=[
        _MODELMETADATARESPONSE_TENSORMETADATA,
        _MODELMETADATARESPONSE_PARAMETERSENTRY,
    ],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=394,
    serialized_end=975,
)


_MODELINFERREQUEST_INFERINPUTTENSOR_PARAMETERSENTRY = _descriptor.Descriptor(
    name="ParametersEntry",
    full_name="inference.ModelInferRequest.InferInputTensor.ParametersEntry",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    create_key=_descriptor._internal_create_key,
    fields=[
        _descriptor.FieldDescriptor(
            name="key",
            full_name="inference.ModelInferRequest.InferInputTensor.ParametersEntry.key",
            index=0,
            number=1,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=b"".decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="value",
            full_name="inference.ModelInferRequest.InferInputTensor.ParametersEntry.value",
            index=1,
            number=2,
            type=11,
            cpp_type=10,
            label=1,
            has_default_value=False,
            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=b"8\001",
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=821,
    serialized_end=897,
)

_MODELINFERREQUEST_INFERINPUTTENSOR = _descriptor.Descriptor(
    name="InferInputTensor",
    full_name="inference.ModelInferRequest.InferInputTensor",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    create_key=_descriptor._internal_create_key,
    fields=[
        _descriptor.FieldDescriptor(
            name="name",
            full_name="inference.ModelInferRequest.InferInputTensor.name",
            index=0,
            number=1,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=b"".decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="datatype",
            full_name="inference.ModelInferRequest.InferInputTensor.datatype",
            index=1,
            number=2,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=b"".decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="shape",
            full_name="inference.ModelInferRequest.InferInputTensor.shape",
            index=2,
            number=3,
            type=3,
            cpp_type=2,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="parameters",
            full_name="inference.ModelInferRequest.InferInputTensor.parameters",
            index=3,
            number=4,
            type=11,
            cpp_type=10,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="contents",
            full_name="inference.ModelInferRequest.InferInputTensor.contents",
            index=4,
            number=5,
            type=11,
            cpp_type=10,
            label=1,
            has_default_value=False,
            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
    ],
    extensions=[],
    nested_types=[
        _MODELINFERREQUEST_INFERINPUTTENSOR_PARAMETERSENTRY,
    ],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=1258,
    serialized_end=1534,
)

_MODELINFERREQUEST_INFERREQUESTEDOUTPUTTENSOR_PARAMETERSENTRY = _descriptor.Descriptor(
    name="ParametersEntry",
    full_name="inference.ModelInferRequest.InferRequestedOutputTensor.ParametersEntry",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    create_key=_descriptor._internal_create_key,
    fields=[
        _descriptor.FieldDescriptor(
            name="key",
            full_name="inference.ModelInferRequest.InferRequestedOutputTensor.ParametersEntry.key",
            index=0,
            number=1,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=b"".decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="value",
            full_name="inference.ModelInferRequest.InferRequestedOutputTensor.ParametersEntry.value",
            index=1,
            number=2,
            type=11,
            cpp_type=10,
            label=1,
            has_default_value=False,
            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=b"8\001",
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=821,
    serialized_end=897,
)

_MODELINFERREQUEST_INFERREQUESTEDOUTPUTTENSOR = _descriptor.Descriptor(
    name="InferRequestedOutputTensor",
    full_name="inference.ModelInferRequest.InferRequestedOutputTensor",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    create_key=_descriptor._internal_create_key,
    fields=[
        _descriptor.FieldDescriptor(
            name="name",
            full_name="inference.ModelInferRequest.InferRequestedOutputTensor.name",
            index=0,
            number=1,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=b"".decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="parameters",
            full_name="inference.ModelInferRequest.InferRequestedOutputTensor.parameters",
            index=1,
            number=2,
            type=11,
            cpp_type=10,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
    ],
    extensions=[],
    nested_types=[
        _MODELINFERREQUEST_INFERREQUESTEDOUTPUTTENSOR_PARAMETERSENTRY,
    ],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=1537,
    serialized_end=1750,
)

_MODELINFERREQUEST_PARAMETERSENTRY = _descriptor.Descriptor(
    name="ParametersEntry",
    full_name="inference.ModelInferRequest.ParametersEntry",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    create_key=_descriptor._internal_create_key,
    fields=[
        _descriptor.FieldDescriptor(
            name="key",
            full_name="inference.ModelInferRequest.ParametersEntry.key",
            index=0,
            number=1,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=b"".decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="value",
            full_name="inference.ModelInferRequest.ParametersEntry.value",
            index=1,
            number=2,
            type=11,
            cpp_type=10,
            label=1,
            has_default_value=False,
            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=b"8\001",
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=821,
    serialized_end=897,
)

_MODELINFERREQUEST = _descriptor.Descriptor(
    name="ModelInferRequest",
    full_name="inference.ModelInferRequest",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    create_key=_descriptor._internal_create_key,
    fields=[
        _descriptor.FieldDescriptor(
            name="model_name",
            full_name="inference.ModelInferRequest.model_name",
            index=0,
            number=1,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=b"".decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="model_version",
            full_name="inference.ModelInferRequest.model_version",
            index=1,
            number=2,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=b"".decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="id",
            full_name="inference.ModelInferRequest.id",
            index=2,
            number=3,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=b"".decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="parameters",
            full_name="inference.ModelInferRequest.parameters",
            index=3,
            number=4,
            type=11,
            cpp_type=10,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="inputs",
            full_name="inference.ModelInferRequest.inputs",
            index=4,
            number=5,
            type=11,
            cpp_type=10,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="outputs",
            full_name="inference.ModelInferRequest.outputs",
            index=5,
            number=6,
            type=11,
            cpp_type=10,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
    ],
    extensions=[],
    nested_types=[
        _MODELINFERREQUEST_INFERINPUTTENSOR,
        _MODELINFERREQUEST_INFERREQUESTEDOUTPUTTENSOR,
        _MODELINFERREQUEST_PARAMETERSENTRY,
    ],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=978,
    serialized_end=1828,
)


_MODELINFERRESPONSE_INFEROUTPUTTENSOR_PARAMETERSENTRY = _descriptor.Descriptor(
    name="ParametersEntry",
    full_name="inference.ModelInferResponse.InferOutputTensor.ParametersEntry",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    create_key=_descriptor._internal_create_key,
    fields=[
        _descriptor.FieldDescriptor(
            name="key",
            full_name="inference.ModelInferResponse.InferOutputTensor.ParametersEntry.key",
            index=0,
            number=1,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=b"".decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="value",
            full_name="inference.ModelInferResponse.InferOutputTensor.ParametersEntry.value",
            index=1,
            number=2,
            type=11,
            cpp_type=10,
            label=1,
            has_default_value=False,
            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=b"8\001",
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=821,
    serialized_end=897,
)

_MODELINFERRESPONSE_INFEROUTPUTTENSOR = _descriptor.Descriptor(
    name="InferOutputTensor",
    full_name="inference.ModelInferResponse.InferOutputTensor",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    create_key=_descriptor._internal_create_key,
    fields=[
        _descriptor.FieldDescriptor(
            name="name",
            full_name="inference.ModelInferResponse.InferOutputTensor.name",
            index=0,
            number=1,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=b"".decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="datatype",
            full_name="inference.ModelInferResponse.InferOutputTensor.datatype",
            index=1,
            number=2,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=b"".decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="shape",
            full_name="inference.ModelInferResponse.InferOutputTensor.shape",
            index=2,
            number=3,
            type=3,
            cpp_type=2,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="parameters",
            full_name="inference.ModelInferResponse.InferOutputTensor.parameters",
            index=3,
            number=4,
            type=11,
            cpp_type=10,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="contents",
            full_name="inference.ModelInferResponse.InferOutputTensor.contents",
            index=4,
            number=5,
            type=11,
            cpp_type=10,
            label=1,
            has_default_value=False,
            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
    ],
    extensions=[],
    nested_types=[
        _MODELINFERRESPONSE_INFEROUTPUTTENSOR_PARAMETERSENTRY,
    ],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=2042,
    serialized_end=2321,
)

_MODELINFERRESPONSE_PARAMETERSENTRY = _descriptor.Descriptor(
    name="ParametersEntry",
    full_name="inference.ModelInferResponse.ParametersEntry",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    create_key=_descriptor._internal_create_key,
    fields=[
        _descriptor.FieldDescriptor(
            name="key",
            full_name="inference.ModelInferResponse.ParametersEntry.key",
            index=0,
            number=1,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=b"".decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="value",
            full_name="inference.ModelInferResponse.ParametersEntry.value",
            index=1,
            number=2,
            type=11,
            cpp_type=10,
            label=1,
            has_default_value=False,
            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=b"8\001",
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=821,
    serialized_end=897,
)

_MODELINFERRESPONSE = _descriptor.Descriptor(
    name="ModelInferResponse",
    full_name="inference.ModelInferResponse",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    create_key=_descriptor._internal_create_key,
    fields=[
        _descriptor.FieldDescriptor(
            name="model_name",
            full_name="inference.ModelInferResponse.model_name",
            index=0,
            number=1,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=b"".decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="model_version",
            full_name="inference.ModelInferResponse.model_version",
            index=1,
            number=2,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=b"".decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="id",
            full_name="inference.ModelInferResponse.id",
            index=2,
            number=3,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=b"".decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="parameters",
            full_name="inference.ModelInferResponse.parameters",
            index=3,
            number=4,
            type=11,
            cpp_type=10,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="outputs",
            full_name="inference.ModelInferResponse.outputs",
            index=4,
            number=5,
            type=11,
            cpp_type=10,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
    ],
    extensions=[],
    nested_types=[
        _MODELINFERRESPONSE_INFEROUTPUTTENSOR,
        _MODELINFERRESPONSE_PARAMETERSENTRY,
    ],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=1831,
    serialized_end=2399,
)


_INFERPARAMETER = _descriptor.Descriptor(
    name="InferParameter",
    full_name="inference.InferParameter",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    create_key=_descriptor._internal_create_key,
    fields=[
        _descriptor.FieldDescriptor(
            name="bool_param",
            full_name="inference.InferParameter.bool_param",
            index=0,
            number=1,
            type=8,
            cpp_type=7,
            label=1,
            has_default_value=False,
            default_value=False,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="int64_param",
            full_name="inference.InferParameter.int64_param",
            index=1,
            number=2,
            type=3,
            cpp_type=2,
            label=1,
            has_default_value=False,
            default_value=0,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="string_param",
            full_name="inference.InferParameter.string_param",
            index=2,
            number=3,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=b"".decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[
        _descriptor.OneofDescriptor(
            name="parameter_choice",
            full_name="inference.InferParameter.parameter_choice",
            index=0,
            containing_type=None,
            create_key=_descriptor._internal_create_key,
            fields=[],
        ),
    ],
    serialized_start=2401,
    serialized_end=2506,
)


_INFERTENSORCONTENTS = _descriptor.Descriptor(
    name="InferTensorContents",
    full_name="inference.InferTensorContents",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    create_key=_descriptor._internal_create_key,
    fields=[
        _descriptor.FieldDescriptor(
            name="bool_contents",
            full_name="inference.InferTensorContents.bool_contents",
            index=0,
            number=1,
            type=8,
            cpp_type=7,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="int_contents",
            full_name="inference.InferTensorContents.int_contents",
            index=1,
            number=2,
            type=5,
            cpp_type=1,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="int64_contents",
            full_name="inference.InferTensorContents.int64_contents",
            index=2,
            number=3,
            type=3,
            cpp_type=2,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="uint_contents",
            full_name="inference.InferTensorContents.uint_contents",
            index=3,
            number=4,
            type=13,
            cpp_type=3,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="uint64_contents",
            full_name="inference.InferTensorContents.uint64_contents",
            index=4,
            number=5,
            type=4,
            cpp_type=4,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="fp32_contents",
            full_name="inference.InferTensorContents.fp32_contents",
            index=5,
            number=6,
            type=2,
            cpp_type=6,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="fp64_contents",
            full_name="inference.InferTensorContents.fp64_contents",
            index=6,
            number=7,
            type=1,
            cpp_type=5,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="bytes_contents",
            full_name="inference.InferTensorContents.bytes_contents",
            index=7,
            number=8,
            type=12,
            cpp_type=9,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=2509,
    serialized_end=2717,
)

_MODELMETADATARESPONSE_TENSORMETADATA_PARAMETERSENTRY.fields_by_name[
    "value"
].message_type = _INFERPARAMETER
_MODELMETADATARESPONSE_TENSORMETADATA_PARAMETERSENTRY.containing_type = (
    _MODELMETADATARESPONSE_TENSORMETADATA
)
_MODELMETADATARESPONSE_TENSORMETADATA.fields_by_name[
    "parameters"
].message_type = _MODELMETADATARESPONSE_TENSORMETADATA_PARAMETERSENTRY
_MODELMETADATARESPONSE_TENSORMETADATA.containing_type = _MODELMETADATARESPONSE
_MODELMETADATARESPONSE_PARAMETERSENTRY.fields_by_name[
    "value"
].message_type = _INFERPARAMETER
_MODELMETADATARESPONSE_PARAMETERSENTRY.containing_type = _MODELMETADATARESPONSE
_MODELMETADATARESPONSE.fields_by_name[
    "inputs"
].message_type = _MODELMETADATARESPONSE_TENSORMETADATA
_MODELMETADATARESPONSE.fields_by_name[
    "outputs"
].message_type = _MODELMETADATARESPONSE_TENSORMETADATA
_MODELMETADATARESPONSE.fields_by_name[
    "parameters"
].message_type = _MODELMETADATARESPONSE_PARAMETERSENTRY
_MODELINFERREQUEST_INFERINPUTTENSOR_PARAMETERSENTRY.fields_by_name[
    "value"
].message_type = _INFERPARAMETER
_MODELINFERREQUEST_INFERINPUTTENSOR_PARAMETERSENTRY.containing_type = (
    _MODELINFERREQUEST_INFERINPUTTENSOR
)
_MODELINFERREQUEST_INFERINPUTTENSOR.fields_by_name[
    "parameters"
].message_type = _MODELINFERREQUEST_INFERINPUTTENSOR_PARAMETERSENTRY
_MODELINFERREQUEST_INFERINPUTTENSOR.fields_by_name[
    "contents"
].message_type = _INFERTENSORCONTENTS
_MODELINFERREQUEST_INFERINPUTTENSOR.containing_type = _MODELINFERREQUEST
_MODELINFERREQUEST_INFERREQUESTEDOUTPUTTENSOR_PARAMETERSENTRY.fields_by_name[
    "value"
].message_type = _INFERPARAMETER
_MODELINFERREQUEST_INFERREQUESTEDOUTPUTTENSOR_PARAMETERSENTRY.containing_type = (
    _MODELINFERREQUEST_INFERREQUESTEDOUTPUTTENSOR
)
_MODELINFERREQUEST_INFERREQUESTEDOUTPUTTENSOR.fields_by_name[
    "parameters"
].message_type = _MODELINFERREQUEST_INFERREQUESTEDOUTPUTTENSOR_PARAMETERSENTRY
_MODELINFERREQUEST_INFERREQUESTEDOUTPUTTENSOR.containing_type = _MODELINFERREQUEST
_MODELINFERREQUEST_PARAMETERSENTRY.fields_by_name[
    "value"
].message_type = _INFERPARAMETER
_MODELINFERREQUEST_PARAMETERSENTRY.containing_type = _MODELINFERREQUEST
_MODELINFERREQUEST.fields_by_name[
    "parameters"
].message_type = _MODELINFERREQUEST_PARAMETERSENTRY
_MODELINFERREQUEST.fields_by_name[
    "inputs"
].message_type = _MODELINFERREQUEST_INFERINPUTTENSOR
_MODELINFERREQUEST.fields_by_name[
    "outputs"
].message_type = _MODELINFERREQUEST_INFERREQUESTEDOUTPUTTENSOR
_MODELINFERRESPONSE_INFEROUTPUTTENSOR_PARAMETERSENTRY.fields_by_name[
    "value"
].message_type = _INFERPARAMETER
_MODELINFERRESPONSE_INFEROUTPUTTENSOR_PARAMETERSENTRY.containing_type = (
    _MODELINFERRESPONSE_INFEROUTPUTTENSOR
)
_MODELINFERRESPONSE_INFEROUTPUTTENSOR.fields_by_name[
    "parameters"
].message_type = _MODELINFERRESPONSE_INFEROUTPUTTENSOR_PARAMETERSENTRY
_MODELINFERRESPONSE_INFEROUTPUTTENSOR.fields_by_name[
    "contents"
].message_type = _INFERTENSORCONTENTS
_MODELINFERRESPONSE_INFEROUTPUTTENSOR.containing_type = _MODELINFERRESPONSE
_MODELINFERRESPONSE_PARAMETERSENTRY.fields_by_name[
    "value"
].message_type = _INFERPARAMETER
_MODELINFERRESPONSE_PARAMETERSENTRY.containing_type = _MODELINFERRESPONSE
_MODELINFERRESPONSE.fields_by_name[
    "parameters"
].message_type = _MODELINFERRESPONSE_PARAMETERSENTRY
_MODELINFERRESPONSE.fields_by_name[
    "outputs"
].message_type = _MODELINFERRESPONSE_INFEROUTPUTTENSOR
_INFERPARAMETER.oneofs_by_name["parameter_choice"].fields.append(
    _INFERPARAMETER.fields_by_name["bool_param"]
)
_INFERPARAMETER.fields_by_name[
    "bool_param"
].containing_oneof = _INFERPARAMETER.oneofs_by_name["parameter_choice"]
_INFERPARAMETER.oneofs_by_name["parameter_choice"].fields.append(
    _INFERPARAMETER.fields_by_name["int64_param"]
)
_INFERPARAMETER.fields_by_name[
    "int64_param"
].containing_oneof = _INFERPARAMETER.oneofs_by_name["parameter_choice"]
_INFERPARAMETER.oneofs_by_name["parameter_choice"].fields.append(
    _INFERPARAMETER.fields_by_name["string_param"]
)
_INFERPARAMETER.fields_by_name[
    "string_param"
].containing_oneof = _INFERPARAMETER.oneofs_by_name["parameter_choice"]
DESCRIPTOR.message_types_by_name["ServerLiveRequest"] = _SERVERLIVEREQUEST
DESCRIPTOR.message_types_by_name["ServerLiveResponse"] = _SERVERLIVERESPONSE
DESCRIPTOR.message_types_by_name["ServerReadyRequest"] = _SERVERREADYREQUEST
DESCRIPTOR.message_types_by_name["ServerReadyResponse"] = _SERVERREADYRESPONSE
DESCRIPTOR.message_types_by_name["ModelReadyRequest"] = _MODELREADYREQUEST
DESCRIPTOR.message_types_by_name["ModelReadyResponse"] = _MODELREADYRESPONSE
DESCRIPTOR.message_types_by_name["ServerMetadataRequest"] = _SERVERMETADATAREQUEST
DESCRIPTOR.message_types_by_name["ServerMetadataResponse"] = _SERVERMETADATARESPONSE
DESCRIPTOR.message_types_by_name["ModelMetadataRequest"] = _MODELMETADATAREQUEST
DESCRIPTOR.message_types_by_name["ModelMetadataResponse"] = _MODELMETADATARESPONSE
DESCRIPTOR.message_types_by_name["ModelInferRequest"] = _MODELINFERREQUEST
DESCRIPTOR.message_types_by_name["ModelInferResponse"] = _MODELINFERRESPONSE
DESCRIPTOR.message_types_by_name["InferParameter"] = _INFERPARAMETER
DESCRIPTOR.message_types_by_name["InferTensorContents"] = _INFERTENSORCONTENTS
_sym_db.RegisterFileDescriptor(DESCRIPTOR)

ServerLiveRequest = _reflection.GeneratedProtocolMessageType(
    "ServerLiveRequest",
    (_message.Message,),
    {
        "DESCRIPTOR": _SERVERLIVEREQUEST,
        "__module__": "dataplane_pb2"
        # @@protoc_insertion_point(class_scope:inference.ServerLiveRequest)
    },
)
_sym_db.RegisterMessage(ServerLiveRequest)

ServerLiveResponse = _reflection.GeneratedProtocolMessageType(
    "ServerLiveResponse",
    (_message.Message,),
    {
        "DESCRIPTOR": _SERVERLIVERESPONSE,
        "__module__": "dataplane_pb2"
        # @@protoc_insertion_point(class_scope:inference.ServerLiveResponse)
    },
)
_sym_db.RegisterMessage(ServerLiveResponse)

ServerReadyRequest = _reflection.GeneratedProtocolMessageType(
    "ServerReadyRequest",
    (_message.Message,),
    {
        "DESCRIPTOR": _SERVERREADYREQUEST,
        "__module__": "dataplane_pb2"
        # @@protoc_insertion_point(class_scope:inference.ServerReadyRequest)
    },
)
_sym_db.RegisterMessage(ServerReadyRequest)

ServerReadyResponse = _reflection.GeneratedProtocolMessageType(
    "ServerReadyResponse",
    (_message.Message,),
    {
        "DESCRIPTOR": _SERVERREADYRESPONSE,
        "__module__": "dataplane_pb2"
        # @@protoc_insertion_point(class_scope:inference.ServerReadyResponse)
    },
)
_sym_db.RegisterMessage(ServerReadyResponse)

ModelReadyRequest = _reflection.GeneratedProtocolMessageType(
    "ModelReadyRequest",
    (_message.Message,),
    {
        "DESCRIPTOR": _MODELREADYREQUEST,
        "__module__": "dataplane_pb2"
        # @@protoc_insertion_point(class_scope:inference.ModelReadyRequest)
    },
)
_sym_db.RegisterMessage(ModelReadyRequest)

ModelReadyResponse = _reflection.GeneratedProtocolMessageType(
    "ModelReadyResponse",
    (_message.Message,),
    {
        "DESCRIPTOR": _MODELREADYRESPONSE,
        "__module__": "dataplane_pb2"
        # @@protoc_insertion_point(class_scope:inference.ModelReadyResponse)
    },
)
_sym_db.RegisterMessage(ModelReadyResponse)

ServerMetadataRequest = _reflection.GeneratedProtocolMessageType(
    "ServerMetadataRequest",
    (_message.Message,),
    {
        "DESCRIPTOR": _SERVERMETADATAREQUEST,
        "__module__": "dataplane_pb2"
        # @@protoc_insertion_point(class_scope:inference.ServerMetadataRequest)
    },
)
_sym_db.RegisterMessage(ServerMetadataRequest)

ServerMetadataResponse = _reflection.GeneratedProtocolMessageType(
    "ServerMetadataResponse",
    (_message.Message,),
    {
        "DESCRIPTOR": _SERVERMETADATARESPONSE,
        "__module__": "dataplane_pb2"
        # @@protoc_insertion_point(class_scope:inference.ServerMetadataResponse)
    },
)
_sym_db.RegisterMessage(ServerMetadataResponse)

ModelMetadataRequest = _reflection.GeneratedProtocolMessageType(
    "ModelMetadataRequest",
    (_message.Message,),
    {
        "DESCRIPTOR": _MODELMETADATAREQUEST,
        "__module__": "dataplane_pb2"
        # @@protoc_insertion_point(class_scope:inference.ModelMetadataRequest)
    },
)
_sym_db.RegisterMessage(ModelMetadataRequest)

ModelMetadataResponse = _reflection.GeneratedProtocolMessageType(
    "ModelMetadataResponse",
    (_message.Message,),
    {
        "TensorMetadata": _reflection.GeneratedProtocolMessageType(
            "TensorMetadata",
            (_message.Message,),
            {
                "ParametersEntry": _reflection.GeneratedProtocolMessageType(
                    "ParametersEntry",
                    (_message.Message,),
                    {
                        "DESCRIPTOR": _MODELMETADATARESPONSE_TENSORMETADATA_PARAMETERSENTRY,
                        "__module__": "dataplane_pb2"
                        # @@protoc_insertion_point(class_scope:inference.ModelMetadataResponse.TensorMetadata.ParametersEntry)
                    },
                ),
                "DESCRIPTOR": _MODELMETADATARESPONSE_TENSORMETADATA,
                "__module__": "dataplane_pb2"
                # @@protoc_insertion_point(class_scope:inference.ModelMetadataResponse.TensorMetadata)
            },
        ),
        "ParametersEntry": _reflection.GeneratedProtocolMessageType(
            "ParametersEntry",
            (_message.Message,),
            {
                "DESCRIPTOR": _MODELMETADATARESPONSE_PARAMETERSENTRY,
                "__module__": "dataplane_pb2"
                # @@protoc_insertion_point(class_scope:inference.ModelMetadataResponse.ParametersEntry)
            },
        ),
        "DESCRIPTOR": _MODELMETADATARESPONSE,
        "__module__": "dataplane_pb2"
        # @@protoc_insertion_point(class_scope:inference.ModelMetadataResponse)
    },
)
_sym_db.RegisterMessage(ModelMetadataResponse)
_sym_db.RegisterMessage(ModelMetadataResponse.TensorMetadata)
_sym_db.RegisterMessage(ModelMetadataResponse.TensorMetadata.ParametersEntry)
_sym_db.RegisterMessage(ModelMetadataResponse.ParametersEntry)

ModelInferRequest = _reflection.GeneratedProtocolMessageType(
    "ModelInferRequest",
    (_message.Message,),
    {
        "InferInputTensor": _reflection.GeneratedProtocolMessageType(
            "InferInputTensor",
            (_message.Message,),
            {
                "ParametersEntry": _reflection.GeneratedProtocolMessageType(
                    "ParametersEntry",
                    (_message.Message,),
                    {
                        "DESCRIPTOR": _MODELINFERREQUEST_INFERINPUTTENSOR_PARAMETERSENTRY,
                        "__module__": "dataplane_pb2"
                        # @@protoc_insertion_point(class_scope:inference.ModelInferRequest.InferInputTensor.ParametersEntry)
                    },
                ),
                "DESCRIPTOR": _MODELINFERREQUEST_INFERINPUTTENSOR,
                "__module__": "dataplane_pb2"
                # @@protoc_insertion_point(class_scope:inference.ModelInferRequest.InferInputTensor)
            },
        ),
        "InferRequestedOutputTensor": _reflection.GeneratedProtocolMessageType(
            "InferRequestedOutputTensor",
            (_message.Message,),
            {
                "ParametersEntry": _reflection.GeneratedProtocolMessageType(
                    "ParametersEntry",
                    (_message.Message,),
                    {
                        "DESCRIPTOR": _MODELINFERREQUEST_INFERREQUESTEDOUTPUTTENSOR_PARAMETERSENTRY,
                        "__module__": "dataplane_pb2"
                        # @@protoc_insertion_point(class_scope:inference.ModelInferRequest.InferRequestedOutputTensor.ParametersEntry)
                    },
                ),
                "DESCRIPTOR": _MODELINFERREQUEST_INFERREQUESTEDOUTPUTTENSOR,
                "__module__": "dataplane_pb2"
                # @@protoc_insertion_point(class_scope:inference.ModelInferRequest.InferRequestedOutputTensor)
            },
        ),
        "ParametersEntry": _reflection.GeneratedProtocolMessageType(
            "ParametersEntry",
            (_message.Message,),
            {
                "DESCRIPTOR": _MODELINFERREQUEST_PARAMETERSENTRY,
                "__module__": "dataplane_pb2"
                # @@protoc_insertion_point(class_scope:inference.ModelInferRequest.ParametersEntry)
            },
        ),
        "DESCRIPTOR": _MODELINFERREQUEST,
        "__module__": "dataplane_pb2"
        # @@protoc_insertion_point(class_scope:inference.ModelInferRequest)
    },
)
_sym_db.RegisterMessage(ModelInferRequest)
_sym_db.RegisterMessage(ModelInferRequest.InferInputTensor)
_sym_db.RegisterMessage(ModelInferRequest.InferInputTensor.ParametersEntry)
_sym_db.RegisterMessage(ModelInferRequest.InferRequestedOutputTensor)
_sym_db.RegisterMessage(ModelInferRequest.InferRequestedOutputTensor.ParametersEntry)
_sym_db.RegisterMessage(ModelInferRequest.ParametersEntry)

ModelInferResponse = _reflection.GeneratedProtocolMessageType(
    "ModelInferResponse",
    (_message.Message,),
    {
        "InferOutputTensor": _reflection.GeneratedProtocolMessageType(
            "InferOutputTensor",
            (_message.Message,),
            {
                "ParametersEntry": _reflection.GeneratedProtocolMessageType(
                    "ParametersEntry",
                    (_message.Message,),
                    {
                        "DESCRIPTOR": _MODELINFERRESPONSE_INFEROUTPUTTENSOR_PARAMETERSENTRY,
                        "__module__": "dataplane_pb2"
                        # @@protoc_insertion_point(class_scope:inference.ModelInferResponse.InferOutputTensor.ParametersEntry)
                    },
                ),
                "DESCRIPTOR": _MODELINFERRESPONSE_INFEROUTPUTTENSOR,
                "__module__": "dataplane_pb2"
                # @@protoc_insertion_point(class_scope:inference.ModelInferResponse.InferOutputTensor)
            },
        ),
        "ParametersEntry": _reflection.GeneratedProtocolMessageType(
            "ParametersEntry",
            (_message.Message,),
            {
                "DESCRIPTOR": _MODELINFERRESPONSE_PARAMETERSENTRY,
                "__module__": "dataplane_pb2"
                # @@protoc_insertion_point(class_scope:inference.ModelInferResponse.ParametersEntry)
            },
        ),
        "DESCRIPTOR": _MODELINFERRESPONSE,
        "__module__": "dataplane_pb2"
        # @@protoc_insertion_point(class_scope:inference.ModelInferResponse)
    },
)
_sym_db.RegisterMessage(ModelInferResponse)
_sym_db.RegisterMessage(ModelInferResponse.InferOutputTensor)
_sym_db.RegisterMessage(ModelInferResponse.InferOutputTensor.ParametersEntry)
_sym_db.RegisterMessage(ModelInferResponse.ParametersEntry)

InferParameter = _reflection.GeneratedProtocolMessageType(
    "InferParameter",
    (_message.Message,),
    {
        "DESCRIPTOR": _INFERPARAMETER,
        "__module__": "dataplane_pb2"
        # @@protoc_insertion_point(class_scope:inference.InferParameter)
    },
)
_sym_db.RegisterMessage(InferParameter)

InferTensorContents = _reflection.GeneratedProtocolMessageType(
    "InferTensorContents",
    (_message.Message,),
    {
        "DESCRIPTOR": _INFERTENSORCONTENTS,
        "__module__": "dataplane_pb2"
        # @@protoc_insertion_point(class_scope:inference.InferTensorContents)
    },
)
_sym_db.RegisterMessage(InferTensorContents)


_MODELMETADATARESPONSE_TENSORMETADATA_PARAMETERSENTRY._options = None
_MODELMETADATARESPONSE_PARAMETERSENTRY._options = None
_MODELINFERREQUEST_INFERINPUTTENSOR_PARAMETERSENTRY._options = None
_MODELINFERREQUEST_INFERREQUESTEDOUTPUTTENSOR_PARAMETERSENTRY._options = None
_MODELINFERREQUEST_PARAMETERSENTRY._options = None
_MODELINFERRESPONSE_INFEROUTPUTTENSOR_PARAMETERSENTRY._options = None
_MODELINFERRESPONSE_PARAMETERSENTRY._options = None

_GRPCINFERENCESERVICE = _descriptor.ServiceDescriptor(
    name="GRPCInferenceService",
    full_name="inference.GRPCInferenceService",
    file=DESCRIPTOR,
    index=0,
    serialized_options=None,
    create_key=_descriptor._internal_create_key,
    serialized_start=2720,
    serialized_end=3228,
    methods=[
        _descriptor.MethodDescriptor(
            name="ServerLive",
            full_name="inference.GRPCInferenceService.ServerLive",
            index=0,
            containing_service=None,
            input_type=_SERVERLIVEREQUEST,
            output_type=_SERVERLIVERESPONSE,
            serialized_options=None,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.MethodDescriptor(
            name="ServerReady",
            full_name="inference.GRPCInferenceService.ServerReady",
            index=1,
            containing_service=None,
            input_type=_SERVERREADYREQUEST,
            output_type=_SERVERREADYRESPONSE,
            serialized_options=None,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.MethodDescriptor(
            name="ModelReady",
            full_name="inference.GRPCInferenceService.ModelReady",
            index=2,
            containing_service=None,
            input_type=_MODELREADYREQUEST,
            output_type=_MODELREADYRESPONSE,
            serialized_options=None,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.MethodDescriptor(
            name="ServerMetadata",
            full_name="inference.GRPCInferenceService.ServerMetadata",
            index=3,
            containing_service=None,
            input_type=_SERVERMETADATAREQUEST,
            output_type=_SERVERMETADATARESPONSE,
            serialized_options=None,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.MethodDescriptor(
            name="ModelMetadata",
            full_name="inference.GRPCInferenceService.ModelMetadata",
            index=4,
            containing_service=None,
            input_type=_MODELMETADATAREQUEST,
            output_type=_MODELMETADATARESPONSE,
            serialized_options=None,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.MethodDescriptor(
            name="ModelInfer",
            full_name="inference.GRPCInferenceService.ModelInfer",
            index=5,
            containing_service=None,
            input_type=_MODELINFERREQUEST,
            output_type=_MODELINFERRESPONSE,
            serialized_options=None,
            create_key=_descriptor._internal_create_key,
        ),
    ],
)
_sym_db.RegisterServiceDescriptor(_GRPCINFERENCESERVICE)

DESCRIPTOR.services_by_name["GRPCInferenceService"] = _GRPCINFERENCESERVICE

# @@protoc_insertion_point(module_scope)
