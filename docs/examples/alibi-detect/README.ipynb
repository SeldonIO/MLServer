{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Serving Alibi-Detect models\n",
    "\n",
    "Out of the box, `mlserver` supports the deployment and serving of `alibi-detect` models.\n",
    "By default, it will assume that these models have been [serialised using `joblib`](https://scikit-learn.org/stable/modules/model_persistence.html).\n",
    "\n",
    "In this example, we will cover how we can train and serialise a simple model, to then serve it using `mlserver`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training\n",
    "\n",
    "The first step will be to train a simple `alibi-detect` model.\n",
    "For that, we will use the [income Classifier example from the `alibi-detect` documentation](https://docs.seldon.io/projects/alibi-detect/en/latest/examples/cd_chi2ks_adult.html) which trains a drift detector."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import alibi\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "adult = alibi.datasets.fetch_adult()\n",
    "X, y = adult.data, adult.target\n",
    "feature_names = adult.feature_names\n",
    "category_map = adult.category_map\n",
    "X.shape, y.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((32561, 12), (32561,))"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "n_ref = 10000\n",
    "n_test = 10000\n",
    "\n",
    "X_ref, X_t0, X_t1 = X[:n_ref], X[n_ref:n_ref + n_test], X[n_ref + n_test:n_ref + 2 * n_test]\n",
    "X_ref.shape, X_t0.shape, X_t1.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((10000, 12), (10000, 12), (10000, 12))"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "categories_per_feature = {f: None for f in list(category_map.keys())}\n",
    "categories_per_feature"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{1: None, 2: None, 3: None, 4: None, 5: None, 6: None, 7: None, 11: None}"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Saving our trained model\n",
    "\n",
    "To save our trained model, we will serialise it using `joblib`.\n",
    "While this is not a perfect approach, it's currently the recommended method to persist models to disk in the [`scikit-learn` documentation](https://scikit-learn.org/stable/modules/model_persistence.html).\n",
    "\n",
    "Our model will be persisted as a file named `mnist-svm.joblib`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import pickle\n",
    "filepath = 'alibi-detector-artifacts/ref_data.pkl'  # change to directory where detector is saved\n",
    "pickle.dump(X_ref, open(filepath,\"wb\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Serving\n",
    "\n",
    "Now that we have trained and saved our model, the next step will be to serve it using `mlserver`. \n",
    "For that, we will need to create 2 configuration files: \n",
    "\n",
    "- `settings.json`: holds the configuration of our server (e.g. ports, log level, etc.).\n",
    "- `model-settings.json`: holds the configuration of our model (e.g. input type, runtime to use, etc.)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### `settings.json`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "%%writefile settings.json\n",
    "{\n",
    "    \"debug\": \"true\"\n",
    "}"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overwriting settings.json\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### `model-settings.json`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "%%writefile model-settings.json\n",
    "{\n",
    "  \"name\": \"income-classifier-cd\",\n",
    "  \"implementation\": \"mlserver_alibi_detect.AlibiDetector\",\n",
    "  \"parameters\": {\n",
    "    \"uri\": \"./alibi-detector-artifacts/ref_data.pkl\",\n",
    "    \"version\": \"v0.1.0\"\n",
    "  }\n",
    "}"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overwriting model-settings.json\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Start serving our model\n",
    "\n",
    "Now that we have our config in-place, we can start the server by running `mlserver start .`. This needs to either be ran from the same directory where our config files are or pointing to the folder where they are.\n",
    "\n",
    "```shell\n",
    "mlserver start .\n",
    "```\n",
    "\n",
    "Since this command will start the server and block the terminal, waiting for requests, this will need to be ran in the background on a separate terminal."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Send test inference request\n",
    "\n",
    "We now have our model being served by `mlserver`.\n",
    "To make sure that everything is working as expected, let's send a request from our test set.\n",
    "\n",
    "For that, we can use the Python types that `mlserver` provides out of box, or we can build our request manually."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from alibi_detect.cd import ChiSquareDrift, TabularDrift\n",
    "cd = TabularDrift(X_ref, p_val=.05, categories_per_feature=categories_per_feature)\n",
    "cd.predict(X_t0,drift_type=\"feature\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'data': {'is_drift': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  'distance': array([1.1600000e-02, 8.4865131e+00, 4.7529316e+00, 3.1599441e+00,\n",
       "         8.1941366e+00, 4.8458526e-01, 5.8652312e-01, 2.1689056e-01,\n",
       "         2.4000001e-03, 1.6000000e-03, 1.1600000e-02, 9.9910326e+00],\n",
       "        dtype=float32),\n",
       "  'p_val': array([0.50786483, 0.38744345, 0.5758693 , 0.36761624, 0.41473988,\n",
       "         0.99267685, 0.9645494 , 0.6414195 , 1.        , 1.        ,\n",
       "         0.50786483, 0.44128036], dtype=float32),\n",
       "  'threshold': 0.05},\n",
       " 'meta': {'name': 'TabularDrift',\n",
       "  'detector_type': 'offline',\n",
       "  'data_type': None}}"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import requests\n",
    "\n",
    "x_0 = X_t0\n",
    "inference_request = {\n",
    "    \"parameters\": {\"drift_type\": \"feature\",},\n",
    "    \"inputs\": [\n",
    "        {\n",
    "            \"name\": \"predict\",\n",
    "            \"shape\": x_0.shape,\n",
    "            \"datatype\": \"FP32\",\n",
    "            \"data\": x_0.tolist(),\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "endpoint = \"http://localhost:8080/v2/models/income-classifier-cd/versions/v0.1.0/infer\"\n",
    "response = requests.post(endpoint, json=inference_request)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import json\n",
    "response_dict = json.loads(response.text)\n",
    "print(response_dict['parameters'],\"\\n\")\n",
    "\n",
    "labels = ['No!', 'Yes!']\n",
    "for f in range(cd.n_features):\n",
    "    stat = 'Chi2' if f in list(categories_per_feature.keys()) else 'K-S'\n",
    "    fname = feature_names[f]\n",
    "    is_drift = response_dict['outputs'][0]['data'][f]\n",
    "    # stat_val, p_val = preds['data']['distance'][f], preds['data']['p_val'][f]\n",
    "    print(f'{fname} -- Drift? {labels[is_drift]}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'content_type': None, 'name': 'TabularDrift', 'data_type': None, 'detector_type': 'offline'} \n",
      "\n",
      "Age -- Drift? No!\n",
      "Workclass -- Drift? No!\n",
      "Education -- Drift? No!\n",
      "Marital Status -- Drift? No!\n",
      "Occupation -- Drift? No!\n",
      "Relationship -- Drift? No!\n",
      "Race -- Drift? No!\n",
      "Sex -- Drift? No!\n",
      "Capital Gain -- Drift? No!\n",
      "Capital Loss -- Drift? No!\n",
      "Hours per week -- Drift? No!\n",
      "Country -- Drift? No!\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('alibi': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "interpreter": {
   "hash": "5377649fd9904e56b1a72eb79a8e3137babc0e642f8d1adb411c1391b7f9d00d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}