{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serving Alibi-Detect models\n",
    "\n",
    "Out of the box, `mlserver` supports the deployment and serving of `alibi-detect` models. In this example, we will cover how we can create a detector configuration to then serve it using `mlserver`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Data and Configuration\n",
    "\n",
    "The first step will be to fetch a reference data for an `alibi-detect` model. For that, we will use the [income Classifier example from the `alibi-detect` documentation](https://docs.seldon.io/projects/alibi-detect/en/latest/examples/cd_chi2ks_adult.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Alibi dependencies for dataset and detector creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install alibi alibi_detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import alibi\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32561, 12), (32561,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult = alibi.datasets.fetch_adult()\n",
    "X, y = adult.data, adult.target\n",
    "feature_names = adult.feature_names\n",
    "category_map = adult.category_map\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 12), (10000, 12), (10000, 12))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_ref = 10000\n",
    "n_test = 10000\n",
    "\n",
    "X_ref, X_t0, X_t1 = X[:n_ref], X[n_ref:n_ref + n_test], X[n_ref + n_test:n_ref + 2 * n_test]\n",
    "X_ref.shape, X_t0.shape, X_t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_per_feature = {f: None for f in list(category_map.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 8), (10000, 8))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = list(category_map.keys())\n",
    "cat_names = [feature_names[_] for _ in list(category_map.keys())]\n",
    "X_ref_cat, X_t0_cat = X_ref[:, cols], X_t0[:, cols]\n",
    "X_ref_cat.shape, X_t0_cat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TabularDrift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating detector and saving configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi_detect.cd import TabularDrift\n",
    "cd = TabularDrift(X_ref, p_val=.05, categories_per_feature=categories_per_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi_detect.utils.saving import save_detector\n",
    "filepath = \"alibi-detector-artifacts/detector_data_tabular\"\n",
    "save_detector(cd, filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting Drift locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.05\n",
      "Age -- Drift? No! -- Chi2 0.012 -- p-value 0.508\n",
      "Workclass -- Drift? No! -- Chi2 8.487 -- p-value 0.387\n",
      "Education -- Drift? No! -- Chi2 4.753 -- p-value 0.576\n",
      "Marital Status -- Drift? No! -- Chi2 3.160 -- p-value 0.368\n",
      "Occupation -- Drift? No! -- Chi2 8.194 -- p-value 0.415\n",
      "Relationship -- Drift? No! -- Chi2 0.485 -- p-value 0.993\n",
      "Race -- Drift? No! -- Chi2 0.587 -- p-value 0.965\n",
      "Sex -- Drift? No! -- Chi2 0.217 -- p-value 0.641\n",
      "Capital Gain -- Drift? No! -- Chi2 0.002 -- p-value 1.000\n",
      "Capital Loss -- Drift? No! -- Chi2 0.002 -- p-value 1.000\n",
      "Hours per week -- Drift? No! -- Chi2 0.012 -- p-value 0.508\n",
      "Country -- Drift? No! -- Chi2 9.991 -- p-value 0.441\n"
     ]
    }
   ],
   "source": [
    "preds = cd.predict(X_t0,drift_type=\"feature\")\n",
    "\n",
    "labels = ['No!', 'Yes!']\n",
    "print(f\"Threshold {preds['data']['threshold']}\")\n",
    "for f in range(cd.n_features):\n",
    "    fname = feature_names[f]\n",
    "    is_drift = (preds['data']['p_val'][f] < preds['data']['threshold']).astype(int)\n",
    "    stat_val, p_val = preds['data']['distance'][f], preds['data']['p_val'][f]\n",
    "    print(f'{fname} -- Drift? {labels[is_drift]} -- Chi2 {stat_val:.3f} -- p-value {p_val:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serving\n",
    "\n",
    "Now that we have the reference data and other configuration parameters, the next step will be to serve it using `mlserver`. \n",
    "For that, we will need to create 2 configuration files: \n",
    "\n",
    "- `settings.json`: holds the configuration of our server (e.g. ports, log level, etc.).\n",
    "- `model-settings.json`: holds the configuration of our model (e.g. input type, runtime to use, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `settings.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting settings.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile settings.json\n",
    "{\n",
    "    \"debug\": \"true\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `model-settings.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model-settings.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile model-settings.json\n",
    "{\n",
    "  \"name\": \"income-classifier-cd\",\n",
    "  \"implementation\": \"mlserver_alibi_detect.AlibiDetectRuntime\",\n",
    "  \"parameters\": {\n",
    "    \"uri\": \"./alibi-detector-artifacts/detector_data_tabular\",\n",
    "    \"version\": \"v0.1.0\"\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start serving our model\n",
    "\n",
    "Now that we have our config in-place, we can start the server by running `mlserver start .`. This needs to either be ran from the same directory where our config files are or pointing to the folder where they are.\n",
    "\n",
    "```shell\n",
    "mlserver start .\n",
    "```\n",
    "\n",
    "Since this command will start the server and block the terminal, waiting for requests, this will need to be ran in the background on a separate terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send test inference request\n",
    "\n",
    "We now have our model being served by `mlserver`.\n",
    "To make sure that everything is working as expected, let's send a request from our test set.\n",
    "\n",
    "For that, we can use the Python types that `mlserver` provides out of box, or we can build our request manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting Drift via MLServer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "inference_request = {\n",
    "    \"inputs\": [\n",
    "        {\n",
    "            \"name\": \"predict\",\n",
    "            \"shape\": X_t0.shape,\n",
    "            \"datatype\": \"FP32\",\n",
    "            \"data\": X_t0.tolist(),\n",
    "        }\n",
    "    ],\n",
    "    \"parameters\":{\n",
    "        \"predict_kwargs\":{\n",
    "            \"drift_type\":\"feature\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "endpoint = \"http://localhost:8080/v2/models/income-classifier-cd/versions/v0.1.0/infer\"\n",
    "response = requests.post(endpoint, json=inference_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'income-classifier-cd', 'model_version': 'v0.1.0', 'id': '72789455-2633-492f-99c8-b47fc5978149', 'parameters': {'content_type': None, 'headers': None, 'predict_kwargs': {}, 'detector_type': 'offline', 'name': 'TabularDrift', 'data_type': None, 'version': '0.8.2dev', 'config_file': '/home/sachin/projects/seldon/MLServer/docs/examples/alibi-detect/alibi-detector-artifacts/detector_data_tabular/config.toml'}, 'outputs': [{'name': 'is_drift', 'shape': [1, 12], 'datatype': 'INT64', 'parameters': None, 'data': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'name': 'distance', 'shape': [1, 12], 'datatype': 'FP32', 'parameters': None, 'data': [0.011599999852478504, 8.486513137817383, 4.752931594848633, 3.1599440574645996, 8.194136619567871, 0.4845852553844452, 0.5865231156349182, 0.21689055860042572, 0.002400000113993883, 0.0015999999595806003, 0.011599999852478504, 9.991032600402832]}, {'name': 'p_val', 'shape': [1, 12], 'datatype': 'FP32', 'parameters': None, 'data': [0.5078648328781128, 0.3874434530735016, 0.5758693218231201, 0.3676162362098694, 0.4147398769855499, 0.992676854133606, 0.9645494222640991, 0.6414194703102112, 1.0, 1.0, 0.5078648328781128, 0.4412803649902344]}, {'name': 'threshold', 'shape': [1], 'datatype': 'FP64', 'parameters': None, 'data': [0.05]}]} \n",
      "\n",
      "Age -- Drift? No!\n",
      "Workclass -- Drift? No!\n",
      "Education -- Drift? No!\n",
      "Marital Status -- Drift? No!\n",
      "Occupation -- Drift? No!\n",
      "Relationship -- Drift? No!\n",
      "Race -- Drift? No!\n",
      "Sex -- Drift? No!\n",
      "Capital Gain -- Drift? No!\n",
      "Capital Loss -- Drift? No!\n",
      "Hours per week -- Drift? No!\n",
      "Country -- Drift? No!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "response_dict = json.loads(response.text)\n",
    "print(response_dict,\"\\n\")\n",
    "\n",
    "labels = ['No!', 'Yes!']\n",
    "for f in range(cd.n_features):\n",
    "    stat = 'Chi2' if f in list(categories_per_feature.keys()) else 'K-S'\n",
    "    fname = feature_names[f]\n",
    "    is_drift = response_dict['outputs'][0]['data'][f]\n",
    "    print(f'{fname} -- Drift? {labels[is_drift]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChiSquareDrift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating detector and saving configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi_detect.cd import ChiSquareDrift\n",
    "cd = ChiSquareDrift(X_ref_cat, p_val=.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi_detect.utils.saving import save_detector\n",
    "filepath = \"alibi-detector-artifacts/detector_data_cat\"\n",
    "save_detector(cd, filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting Drift locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.05\n",
      "Workclass -- Drift? No! -- Chi2 8.487 -- p-value 0.387\n",
      "Education -- Drift? No! -- Chi2 4.753 -- p-value 0.576\n",
      "Marital Status -- Drift? No! -- Chi2 3.160 -- p-value 0.368\n",
      "Occupation -- Drift? No! -- Chi2 8.194 -- p-value 0.415\n",
      "Relationship -- Drift? No! -- Chi2 0.485 -- p-value 0.993\n",
      "Race -- Drift? No! -- Chi2 0.587 -- p-value 0.965\n",
      "Sex -- Drift? No! -- Chi2 0.217 -- p-value 0.641\n",
      "Country -- Drift? No! -- Chi2 9.991 -- p-value 0.441\n"
     ]
    }
   ],
   "source": [
    "preds = cd.predict(X_t0_cat,drift_type=\"feature\")\n",
    "\n",
    "labels = ['No!', 'Yes!']\n",
    "print(f\"Threshold {preds['data']['threshold']}\")\n",
    "for f in range(cd.n_features):\n",
    "    fname = cat_names[f]\n",
    "    is_drift = (preds['data']['p_val'][f] < preds['data']['threshold']).astype(int)\n",
    "    stat_val, p_val = preds['data']['distance'][f], preds['data']['p_val'][f]\n",
    "    print(f'{fname} -- Drift? {labels[is_drift]} -- Chi2 {stat_val:.3f} -- p-value {p_val:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serving\n",
    "\n",
    "Now that we have the reference data and other configuration parameters, the next step will be to serve it using `mlserver`. \n",
    "For that, we will need to create 2 configuration files: \n",
    "\n",
    "- `settings.json`: holds the configuration of our server (e.g. ports, log level, etc.).\n",
    "- `model-settings.json`: holds the configuration of our model (e.g. input type, runtime to use, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `settings.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting settings.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile settings.json\n",
    "{\n",
    "    \"debug\": \"true\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `model-settings.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model-settings.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile model-settings.json\n",
    "{\n",
    "  \"name\": \"income-classifier-cd\",\n",
    "  \"implementation\": \"mlserver_alibi_detect.AlibiDetectRuntime\",\n",
    "  \"parameters\": {\n",
    "    \"uri\": \"./alibi-detector-artifacts/detector_data_cat\",\n",
    "    \"version\": \"v0.1.0\"\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start serving our model\n",
    "\n",
    "Now that we have our config in-place, we can start the server by running `mlserver start .`. This needs to either be ran from the same directory where our config files are or pointing to the folder where they are.\n",
    "\n",
    "```shell\n",
    "mlserver start .\n",
    "```\n",
    "\n",
    "Since this command will start the server and block the terminal, waiting for requests, this will need to be ran in the background on a separate terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send test inference request\n",
    "\n",
    "We now have our model being served by `mlserver`.\n",
    "To make sure that everything is working as expected, let's send a request from our test set.\n",
    "\n",
    "For that, we can use the Python types that `mlserver` provides out of box, or we can build our request manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "inference_request = {    \n",
    "    \"inputs\": [\n",
    "        {\n",
    "            \"name\": \"predict\",\n",
    "            \"shape\": X_t0_cat.shape,\n",
    "            \"datatype\": \"FP32\",\n",
    "            \"data\": X_t0_cat.tolist(),\n",
    "        }\n",
    "    ],\n",
    "    \"parameters\":{\n",
    "        \"predict_kwargs\":{\n",
    "            \"drift_type\":\"feature\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "endpoint = \"http://localhost:8080/v2/models/income-classifier-cd/versions/v0.1.0/infer\"\n",
    "response = requests.post(endpoint, json=inference_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'income-classifier-cd', 'model_version': 'v0.1.0', 'id': '4daca232-95b3-44fa-bd15-c286cdf39d5c', 'parameters': {'content_type': None, 'headers': None, 'predict_kwargs': {}, 'detector_type': 'offline', 'config_file': '/home/sachin/projects/seldon/MLServer/docs/examples/alibi-detect/alibi-detector-artifacts/detector_data_cat/config.toml', 'version': '0.8.2dev', 'name': 'ChiSquareDrift', 'data_type': None}, 'outputs': [{'name': 'is_drift', 'shape': [1, 8], 'datatype': 'INT64', 'parameters': None, 'data': [0, 0, 0, 0, 0, 0, 0, 0]}, {'name': 'distance', 'shape': [1, 8], 'datatype': 'FP32', 'parameters': None, 'data': [8.486513137817383, 4.752931594848633, 3.1599440574645996, 8.194136619567871, 0.4845852553844452, 0.5865231156349182, 0.21689055860042572, 9.991032600402832]}, {'name': 'p_val', 'shape': [1, 8], 'datatype': 'FP32', 'parameters': None, 'data': [0.3874434530735016, 0.5758693218231201, 0.3676162362098694, 0.4147398769855499, 0.992676854133606, 0.9645494222640991, 0.6414194703102112, 0.4412803649902344]}, {'name': 'threshold', 'shape': [1], 'datatype': 'FP64', 'parameters': None, 'data': [0.05]}]} \n",
      "\n",
      "Age -- Drift? No!\n",
      "Workclass -- Drift? No!\n",
      "Education -- Drift? No!\n",
      "Marital Status -- Drift? No!\n",
      "Occupation -- Drift? No!\n",
      "Relationship -- Drift? No!\n",
      "Race -- Drift? No!\n",
      "Sex -- Drift? No!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "response_dict = json.loads(response.text)\n",
    "print(response_dict,\"\\n\")\n",
    "\n",
    "labels = ['No!', 'Yes!']\n",
    "for f in range(cd.n_features):\n",
    "    stat = 'Chi2' if f in list(categories_per_feature.keys()) else 'K-S'\n",
    "    fname = feature_names[f]\n",
    "    is_drift = response_dict['outputs'][0]['data'][f]\n",
    "    print(f'{fname} -- Drift? {labels[is_drift]}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5377649fd9904e56b1a72eb79a8e3137babc0e642f8d1adb411c1391b7f9d00d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('alibi': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
