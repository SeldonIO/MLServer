{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c519626",
   "metadata": {},
   "source": [
    "# Serving HuggingFace Transformer Models\n",
    "\n",
    "Out of the box, MLServer supports the deployment and serving of HuggingFace Transformer models with the following features:\n",
    "\n",
    "- Loading of Transformer Model artifacts from Hub.\n",
    "- Supports Optimized models using Optimum library\n",
    "\n",
    "In this example, we will showcase some of this features using an example model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "655ea442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, 'w') as f:\n",
    "        f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fed35e",
   "metadata": {},
   "source": [
    "## Serving\n",
    "\n",
    "Now that we have trained and serialised our model, we are ready to start serving it.\n",
    "For that, the initial step will be to set up a `model-settings.json` that instructs MLServer to load our artifact using the HuggingFace Inference Runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6df62443",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writetemplate ./model-settings.json\n",
    "{{\n",
    "    \"name\": \"gpt2-model\",\n",
    "    \"implementation\": \"mlserver_huggingface.HuggingFaceRuntime\",\n",
    "    \"parameters\": {{\n",
    "        \"extra\": {{\n",
    "            \"task\": \"text-generation\"\n",
    "        }}\n",
    "    }}\n",
    "}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a6e8b2",
   "metadata": {},
   "source": [
    "Now that we have our config in-place, we can start the server by running `mlserver start .`. This needs to either be ran from the same directory where our config files are or pointing to the folder where they are.\n",
    "\n",
    "```shell\n",
    "mlserver start .\n",
    "```\n",
    "\n",
    "Since this command will start the server and block the terminal, waiting for requests, this will need to be ran in the background on a separate terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b664c591",
   "metadata": {},
   "source": [
    "### Send test inference request\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "759ad7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'gpt2-model',\n",
       " 'model_version': None,\n",
       " 'id': 'e07b488b-7730-4a52-a7a0-76bfeaeeffea',\n",
       " 'parameters': None,\n",
       " 'outputs': [{'name': 'huggingface',\n",
       "   'shape': [1],\n",
       "   'datatype': 'BYTES',\n",
       "   'parameters': None,\n",
       "   'data': ['[[{\"generated_text\": \"this is an input device (i.e. a USB), it will be able to interpret messages sent to the USB through the Bluetooth protocol.\\\\n\\\\nWhen the input device is plugged in it will ask for data from your iPhone using the NFC,\"}]]']}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "inference_request = {\n",
    "    \"inputs\": [\n",
    "        {\n",
    "          \"name\": \"huggingface\",\n",
    "          \"shape\": [1],\n",
    "          \"datatype\": \"BYTES\",\n",
    "          \"data\": [\"this is an input\"],\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "endpoint = \"http://localhost:8080/v2/models/gpt2-model/infer\"\n",
    "response = requests.post(endpoint, json=inference_request)\n",
    "\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d185281",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
