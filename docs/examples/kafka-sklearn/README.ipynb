{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serving Scikit-Learn models using Kafka Protocol\n",
    "\n",
    "Out of the box, `mlserver` supports the deployment and serving of `scikit-learn` models.\n",
    "By default, it will assume that these models have been [serialised using `joblib`](https://scikit-learn.org/stable/modules/model_persistence.html).\n",
    "\n",
    "In this example, we will cover how we can train and serialise a simple model, to then serve it using `mlserver`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Kafka\n",
    "\n",
    "We are going to start by running a simple local docker deployment of kafka that we can test against. This will be a minimal cluster that will consist of a single zookeeper node and a single broker.\n",
    "\n",
    "You need to have Java installed in order for it to work correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://apache.mirrors.nublue.co.uk/kafka/2.8.0/kafka_2.12-2.8.0.tgz\n",
    "!tar -zxvf kafka_2.12-2.8.0.tgz\n",
    "!./kafka_2.12-2.8.0/bin/kafka-storage.sh format -t OXn8RTSlQdmxwjhKnSB_6A -c ./kafka_2.12-2.8.0/config/kraft/server.properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the no-zookeeper kafka broker\n",
    "\n",
    "Now you can just run it with the following command outside the terminal:\n",
    "```\n",
    "!./kafka_2.12-2.8.0/bin/kafka-server-start.sh ./kafka_2.12-2.8.0/config/kraft/server.properties\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Topics\n",
    "\n",
    "Now we can create the input and output topics required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while executing topic command : Topic with this name already exists.\n",
      "[2021-08-05 04:32:32,710] ERROR org.apache.kafka.common.errors.TopicExistsException: Topic with this name already exists.\n",
      " (kafka.admin.TopicCommand$)\n",
      "Error while executing topic command : Topic with this name already exists.\n",
      "[2021-08-05 04:32:34,590] ERROR org.apache.kafka.common.errors.TopicExistsException: Topic with this name already exists.\n",
      " (kafka.admin.TopicCommand$)\n"
     ]
    }
   ],
   "source": [
    "!./kafka_2.12-2.8.0/bin/kafka-topics.sh --create --topic mlserver-input --partitions 1 --replication-factor 1 --bootstrap-server localhost:9092\n",
    "!./kafka_2.12-2.8.0/bin/kafka-topics.sh --create --topic mlserver-output --partitions 1 --replication-factor 1 --bootstrap-server localhost:9092"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "The first step will be to train a simple `scikit-learn` model.\n",
    "For that, we will use the [MNIST example from the `scikit-learn` documentation](https://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html) which trains an SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(gamma=0.001)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original source code and more details can be found in:\n",
    "# https://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# The digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "# Create a classifier: a support vector classifier\n",
    "classifier = svm.SVC(gamma=0.001)\n",
    "\n",
    "# Split data into train and test subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, digits.target, test_size=0.5, shuffle=False)\n",
    "\n",
    "# We learn the digits on the first half of the digits\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving our trained model\n",
    "\n",
    "To save our trained model, we will serialise it using `joblib`.\n",
    "While this is not a perfect approach, it's currently the recommended method to persist models to disk in the [`scikit-learn` documentation](https://scikit-learn.org/stable/modules/model_persistence.html).\n",
    "\n",
    "Our model will be persisted as a file named `mnist-svm.joblib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mnist-svm.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "model_file_name = \"mnist-svm.joblib\"\n",
    "joblib.dump(classifier, model_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serving\n",
    "\n",
    "Now that we have trained and saved our model, the next step will be to serve it using `mlserver`. \n",
    "For that, we will need to create 2 configuration files: \n",
    "\n",
    "- `settings.json`: holds the configuration of our server (e.g. ports, log level, etc.).\n",
    "- `model-settings.json`: holds the configuration of our model (e.g. input type, runtime to use, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `settings.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting settings.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile settings.json\n",
    "{\n",
    "    \"debug\": \"true\",\n",
    "    \"kafka_enable\": \"true\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `model-settings.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model-settings.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile model-settings.json\n",
    "{\n",
    "    \"name\": \"mnist-svm\",\n",
    "    \"implementation\": \"mlserver_sklearn.SKLearnModel\",\n",
    "    \"parameters\": {\n",
    "        \"uri\": \"./mnist-svm.joblib\",\n",
    "        \"version\": \"v0.1.0\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start serving our model\n",
    "\n",
    "Now that we have our config in-place, we can start the server by running `mlserver start .`. This needs to either be ran from the same directory where our config files are or pointing to the folder where they are.\n",
    "\n",
    "```shell\n",
    "mlserver start .\n",
    "```\n",
    "\n",
    "Since this command will start the server and block the terminal, waiting for requests, this will need to be ran in the background on a separate terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send test inference request\n",
    "\n",
    "We now have our model being served by `mlserver`.\n",
    "To make sure that everything is working as expected, let's send a request from our test set.\n",
    "\n",
    "For that, we can use the Python types that `mlserver` provides out of box, or we can build our request manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'mnist-svm',\n",
       " 'model_version': 'v0.1.0',\n",
       " 'id': '53e3c2d5-456c-41a6-9e7f-6ba0ef717c3c',\n",
       " 'parameters': None,\n",
       " 'outputs': [{'name': 'predict',\n",
       "   'shape': [1],\n",
       "   'datatype': 'INT64',\n",
       "   'parameters': None,\n",
       "   'data': [8]}]}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "x_0 = X_test[0:1]\n",
    "inference_request = {\n",
    "    \"inputs\": [\n",
    "        {\n",
    "          \"name\": \"predict\",\n",
    "          \"shape\": x_0.shape,\n",
    "          \"datatype\": \"FP32\",\n",
    "          \"data\": x_0.tolist()\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "endpoint = \"http://localhost:8080/v2/models/mnist-svm/versions/v0.1.0/infer\"\n",
    "response = requests.post(endpoint, json=inference_request)\n",
    "\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<kafka.producer.future.FutureRecordMetadata at 0x7f8da94d1250>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from kafka import KafkaProducer\n",
    "\n",
    "producer = KafkaProducer(bootstrap_servers=\"localhost:9092\")\n",
    "\n",
    "headers = {\n",
    "    \"mlserver-model\": b\"mnist-svm\",\n",
    "    \"mlserver-version\": b\"v0.1.0\",\n",
    "}\n",
    "\n",
    "producer.send(\n",
    "    \"mlserver-input\",\n",
    "    json.dumps(inference_request).encode(\"utf-8\"),\n",
    "    headers=list(headers.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:kafka.coordinator.consumer:group_id is None: disabling auto-commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key: None\n",
      "value: b'{\"model_name\":\"mnist-svm\",\"model_version\":\"v0.1.0\",\"id\":\"f2a22555-43bc-40c2-9695-41602285a068\",\"parameters\":null,\"outputs\":[{\"name\":\"predict\",\"shape\":[1],\"datatype\":\"INT64\",\"parameters\":null,\"data\":[8]}]}'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from kafka import KafkaConsumer\n",
    "\n",
    "consumer = KafkaConsumer(\n",
    "    \"mlserver-output\",\n",
    "    bootstrap_servers=\"localhost:9092\",\n",
    "    auto_offset_reset=\"earliest\")\n",
    "\n",
    "for msg in consumer:\n",
    "    print(f\"key: {msg.key}\")\n",
    "    print(f\"value: {msg.value}\\n\")\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
